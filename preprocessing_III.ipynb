{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocessing III\n",
    "\n",
    "This notebook converts the data output from preprocessing II into the right format, making it ready to train models on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Conversion\n",
    "General one-hot encoding, for which no specific information about the feature is needed. One important thing here is that all files need to have the same columns. So, they all need to be encoded on the same unique values, since different files may have different values. Therefore, we import all files to collect their unique values and store this in a list of sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing  unknown\n",
      "Adding unique values for  unknown\n",
      "Importing  white\n",
      "Adding unique values for  white\n",
      "Importing  other\n",
      "Adding unique values for  other\n",
      "Importing  asian\n",
      "Adding unique values for  asian\n",
      "Importing  hispanic_latino\n",
      "Adding unique values for  hispanic_latino\n",
      "Importing  black_african_american\n",
      "Adding unique values for  black_african_american\n",
      "Importing  unable_to_obtain\n",
      "Adding unique values for  unable_to_obtain\n",
      "Importing  american_indian_alaska_native\n",
      "Adding unique values for  american_indian_alaska_native\n"
     ]
    }
   ],
   "source": [
    "ethnic_group_names = ['unknown', 'white', 'other', 'asian', 'hispanic_latino', 'black_african_american', 'unable_to_obtain', 'american_indian_alaska_native']\n",
    "categorical_columns = ['admission_type', 'admission_location', 'insurance', 'marital_status', 'gender']\n",
    "\n",
    "# initiate sets with unique values for each feature\n",
    "categorical_sets = []\n",
    "for category in categorical_columns:\n",
    "    categorical_sets.append(set())\n",
    "\n",
    "# iterate over all datasets and add their feature values to the sets\n",
    "for name in ethnic_group_names:\n",
    "    # import data\n",
    "    print('Importing ', name)\n",
    "    df = pd.read_csv('data/preprocessing_II/' + name + '.csv')\n",
    "\n",
    "    # add unqiue values for all features\n",
    "    print('Adding unique values for ', name)\n",
    "    for i in range(len(categorical_columns)):\n",
    "        categorical_sets[i].update(df[categorical_columns[i]].unique())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_categorical (df):\n",
    "    for i in range(len(categorical_columns)):\n",
    "        for value in categorical_sets[i]:\n",
    "            # replace nan values with category 'unknown'\n",
    "            if pd.isna(value):\n",
    "                value = 'unknown'\n",
    "\n",
    "            # column name e.g. gender_m or marital_status_divorced\n",
    "            value_name = value.replace(' ', '_')\n",
    "            column_name = categorical_columns[i] + \"_\" + value_name.lower()\n",
    "            # one-hot encoding with True and False\n",
    "            df[column_name] = np.where(df[categorical_columns[i]] == value, True, False)\n",
    "       \n",
    "        # remove old column\n",
    "        df = df.drop(columns=[categorical_columns[i]])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datetime Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_datetime (df):\n",
    "    datetime_columns = ['admittime', 'edregtime', 'emar_charttime', 'lab_charttime']\n",
    "\n",
    "    for column in datetime_columns:\n",
    "        df[column] = pd.to_datetime(df[column])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Float Conversion\n",
    "\n",
    "All counts are integer values, but are still represented as floats, due to NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_float (df):\n",
    "    float_columns = ['icd_code_count', 'emar_count', 'lab_count']\n",
    "\n",
    "    for column in float_columns:\n",
    "        df[column] = df[column].fillna(0)\n",
    "        df[column] = df[column].astype('int64')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eMAR Medication\n",
    "### One-hot encoding with specific information selection:\n",
    "\n",
    "Most common causes for kidney disease are:\n",
    "1. diabetes\n",
    "2. high blood pressure\n",
    "3. high cholestorol\n",
    "\n",
    "Related medicines are:\n",
    "1. Insulin\n",
    "2. ACE inhabitors such as Enalapril, Captopril, Lisinopril and Ramipril\n",
    "3. Calcium blockers such as amLODIPine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emar_medicine (df):\n",
    "    # initiate unique medicine count column\n",
    "    df['emar_medicine_count'] = 0\n",
    "\n",
    "\n",
    "    # initiate new boolean columns\n",
    "    df['emar_contains_insulin'] = False\n",
    "    df['emar_contains_ace_inhabitors'] = False\n",
    "    df['emar_contains_calcium_blockers'] = False\n",
    "\n",
    "    # check for medicine in the array of medications\n",
    "    # multiple types of medicine may occur (e.g. insuline and ace inhabitors)\n",
    "    for i in range(len(df)):\n",
    "        if not pd.isna(df['emar_medications'][i]):\n",
    "            medications = df['emar_medications'][i]\n",
    "\n",
    "            # unique medicine count\n",
    "            # filter and convert string to set to get unique values\n",
    "            medications_filtered = medications.replace('[', '')\n",
    "            medications_filtered = medications_filtered.replace(']', '')\n",
    "            medications_filtered = medications_filtered.replace('\\'\\'', '')\n",
    "            df.loc[i, 'emar_medicine_count'] = len(set(medications_filtered.split(',')))\n",
    "            \n",
    "            # insulin\n",
    "            if 'Insulin' in medications:\n",
    "                df.loc[i, 'emar_contains_insulin'] = True\n",
    "\n",
    "            # ace inhabitors\n",
    "            if 'Enalapril' in medications:\n",
    "                df.loc[i, 'emar_contains_ace_inhabitors'] = True\n",
    "            elif 'Captopril' in medications:\n",
    "                df.loc[i, 'emar_contains_ace_inhabitors'] = True\n",
    "            elif 'Lisinopril' in medications:\n",
    "                df.loc[i, 'emar_contains_ace_inhabitors'] = True\n",
    "            elif 'Ramipril' in medications:\n",
    "                df.loc[i, 'emar_contains_ace_inhabitors'] = True\n",
    "\n",
    "            # calcium blockers\n",
    "            if 'amLODIPine' in medications:\n",
    "                df.loc[i, 'emar_contains_calcium_blockers'] = True\n",
    "\n",
    "    # drop old column\n",
    "    df = df.drop(columns=['emar_medications'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eMAR Events\n",
    "### One-hot encoding with specific information selection:\n",
    "\n",
    "Most prescribed drugs are 'administred', but it sometimes they are not. These are the interesting cases, as doctors might stop a certain prescription due to adverse events for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emar_events (df):\n",
    "    # initiate new boolean columns\n",
    "    df['emar_contains_not_given'] = False\n",
    "    df['emar_contains_not_flushed'] = False\n",
    "    df['emar_contains_stopped'] = False\n",
    "    df['emar_contains_not_started'] = False\n",
    "\n",
    "    # check for event in array of events\n",
    "    # multiple events can occur for the same patient, as the patient may take multiple drugs at the time\n",
    "    for i in range(len(df)):\n",
    "        if not pd.isna(df['emar_events'][i]):\n",
    "            events = df['emar_events'][i]\n",
    "\n",
    "            if 'Not Given' in events:\n",
    "                df.loc[i, 'emar_contains_not_given'] = True\n",
    "            if 'Not Flushed' in events:\n",
    "                df.loc[i, 'emar_contains_not_flushed'] = True\n",
    "            if 'Stopped' in events:\n",
    "                df.loc[i, 'emar_contains_stopped'] = True\n",
    "            if 'Not Started' in events:\n",
    "                df.loc[i, 'emar_contains_not_started'] = True\n",
    "\n",
    "    # drop old column\n",
    "    df = df.drop(columns=['emar_events'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Flag\n",
    "### One-hot encoding with specific information selection:\n",
    "\n",
    "Either 'abnormal' or nan. We want to count the occurances of abnormal flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lab_flag (df):\n",
    "    # initiate boolean column\n",
    "    df['abnormal_lab_flags'] = 0\n",
    "    \n",
    "    # check whether it has abnormal\n",
    "    for i in range(len(df)):\n",
    "        if not pd.isna(df['lab_flag'][i]):\n",
    "            flags = df['lab_flag'][i]\n",
    "\n",
    "            df.loc[i, 'abnormal_lab_flags'] = flags.count('abnormal')\n",
    "    \n",
    "    # drop old column\n",
    "    df = df.drop(columns=['lab_flag'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Comments\n",
    "### One-hot encoding with specific information selection:\n",
    "\n",
    "Either a detailed comment (string) or ',' or nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lab_comments (df):\n",
    "    # initiate boolean column\n",
    "    df['has_lab_comment'] = False\n",
    "\n",
    "    # set value to false\n",
    "    for i in range(len(df)):\n",
    "        if not pd.isna(df['lab_comments'][i]):\n",
    "            comments = df['lab_comments'][i]\n",
    "            \n",
    "            # filter out empty comments\n",
    "            comments_filtered = comments.replace('\\\"', '')\n",
    "            comments_filtered = comments_filtered.replace('\\'', '')\n",
    "            comments_filtered = comments_filtered.replace(',', '')\n",
    "            comments_filtered = comments_filtered.replace(' ', '')\n",
    "\n",
    "            # if there are non-empty comments set to True\n",
    "            if comments_filtered != []:\n",
    "                df.loc[i, 'has_lab_comment'] = True\n",
    "    \n",
    "    # drop old column\n",
    "    df = df.drop(columns=['lab_comments'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Priority\n",
    "### One-hot encoding with specific information selection:\n",
    "\n",
    "Either a STAT or ROUTINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lab_priority (df):\n",
    "    # initiate new boolean columns\n",
    "    df['lab_priority_stat'] = False\n",
    "    df['lab_priority_routine'] = False\n",
    "\n",
    "    # check for priority in array of priorities\n",
    "    for i in range(len(df)):\n",
    "        if not pd.isna(df['lab_priority'][i]):\n",
    "            priorities = df['lab_priority'][i]\n",
    "\n",
    "            if 'STAT' in priorities:\n",
    "                df.loc[i, 'lab_priority_stat'] = True\n",
    "            if 'ROUTINE' in priorities:\n",
    "                df.loc[i, 'lab_priority_routine'] = True\n",
    "\n",
    "    # drop old column\n",
    "    df = df.drop(columns=['lab_priority'])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_all (df_name):\n",
    "    # import\n",
    "    print('Importing ', df_name)\n",
    "    df = pd.read_csv('data/preprocessing_II/' + df_name + '.csv')\n",
    "\n",
    "    # drop columns\n",
    "    print('Converting ', df_name)\n",
    "    df = df.drop(columns=['Unnamed: 0', 'ethnicity'])\n",
    "\n",
    "    # general format conversions\n",
    "    df = convert_categorical(df)\n",
    "    df = convert_datetime(df)\n",
    "    df = convert_float(df)\n",
    "\n",
    "    # specific (one-hot) encodings\n",
    "    df = convert_emar_medicine(df)\n",
    "    df = convert_emar_events(df)\n",
    "    df = convert_lab_flag(df)\n",
    "    df = convert_lab_comments(df)\n",
    "    df = convert_lab_priority(df)\n",
    "    \n",
    "    # save to .csv\n",
    "    print('Saving .csv for ', df_name)\n",
    "    df.to_csv(\"data/preprocessing_III/\" + df_name + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing  unknown\n",
      "Converting  unknown\n",
      "Saving .csv for  unknown\n",
      "Importing  white\n",
      "Converting  white\n",
      "Saving .csv for  white\n",
      "Importing  other\n",
      "Converting  other\n",
      "Saving .csv for  other\n",
      "Importing  asian\n",
      "Converting  asian\n",
      "Saving .csv for  asian\n",
      "Importing  hispanic_latino\n",
      "Converting  hispanic_latino\n",
      "Saving .csv for  hispanic_latino\n",
      "Importing  black_african_american\n",
      "Converting  black_african_american\n",
      "Saving .csv for  black_african_american\n",
      "Importing  unable_to_obtain\n",
      "Converting  unable_to_obtain\n",
      "Saving .csv for  unable_to_obtain\n",
      "Importing  american_indian_alaska_native\n",
      "Converting  american_indian_alaska_native\n",
      "Saving .csv for  american_indian_alaska_native\n"
     ]
    }
   ],
   "source": [
    "for name in ethnic_group_names:\n",
    "    convert_all(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('sklearn-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "34e7f5b862476ca5b132d6fa3a551e06a58745cd7626854c77bc546bf08a4906"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
