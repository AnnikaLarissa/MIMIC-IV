{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocessing III\n",
    "\n",
    "This notebook extends the data output from preprocessing II, making it ready to train models on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "path = './data/preprocessing_II'\n",
    "files = glob.glob(path + \"/*.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import data\n",
    "\n",
    "Data is read from preprocessing II output files. For a quick analysis of the data distribution, the fraction of patients suffering from kidney issues is printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def readFiles(csv_files):\n",
    "    return [pd.read_csv(file) for file in csv_files]\n",
    "\n",
    "ethn_list = readFiles(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Print ethnicity order and percentage of patients suffering from kidney disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t22% \tamerican_indian_alaska_native\n",
      "1\t11% \tasian\n",
      "2\t22% \tblack_african_american\n",
      "3\t15% \thispanic_latino\n",
      "4\t14% \tother\n",
      "5\t7% \tunable_to_obtain\n",
      "6\t14% \tunknown\n",
      "7\t18% \twhite\n"
     ]
    }
   ],
   "source": [
    "def printEthnicities(csv_files, df_list):\n",
    "    for counter in range(len(csv_files)):\n",
    "        print(counter.__str__() + \"\\t\"  + (int(sum(df_list[counter]['has_kidney_issue'])/len(df_list[counter])*100)).__str__() + \"% \\t\" + csv_files[counter].split(\"\\\\\")[1].split(\".\")[0])\n",
    "\n",
    "printEthnicities(files, ethn_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getTestDf(df_list):\n",
    "    return df_list[0]\n",
    "\n",
    "df = getTestDf(ethn_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Processing types of columns and categorical variables\n",
    "\n",
    "The columns for 'emar_events', 'lab_priority' and 'lab_comments' are dropped as these do not contain interpretable data with predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datetime = ['admittime', 'edregtime', 'emar_charttime', 'lab_charttime']\n",
    "ints = ['icd_code_count', 'emar_count', 'lab_count']\n",
    "one_hots = ['admission_type', 'admission_location', 'insurance', 'marital_status', 'gender']\n",
    "drop_cols = ['ethnicity', 'emar_events', 'lab_priority', 'lab_comments', 'lab_flag', 'Unnamed: 0', 'hadm_id', 'subject_id', 'edregtime', 'emar_charttime', 'lab_charttime']\n",
    "\n",
    "def convert(type, dfs, cols):\n",
    "    for df in dfs:\n",
    "        for col in cols:\n",
    "            df[col] = df[col].astype(type)\n",
    "    return dfs\n",
    "\n",
    "def findAllUniques(dfs, col):\n",
    "    uniques = set()\n",
    "    for df in dfs:\n",
    "        for item in df[col].unique():\n",
    "            uniques.add(item)\n",
    "    return uniques\n",
    "\n",
    "def oneHot(dfs, cols):\n",
    "    for col in cols:\n",
    "        vals = findAllUniques(dfs, col)\n",
    "        for df in range(len(dfs)):\n",
    "            if len(vals) > 2:\n",
    "                for val in vals:\n",
    "                    dfs[df][val] = np.where(dfs[df][col]==val, True, False)\n",
    "\n",
    "                dfs[df] = dfs[df].drop(col, axis=1)\n",
    "            else:\n",
    "                dfs[df][col] = np.where(dfs[df][col]==val[0], True, False)\n",
    "    return dfs\n",
    "\n",
    "def dropCols(dfs, cols):\n",
    "    for col in cols:\n",
    "        for df in range(len(dfs)):\n",
    "            dfs[df] = dfs[df].drop(col, axis=1)\n",
    "    return dfs\n",
    "\n",
    "ethn_list = convert('datetime64', ethn_list, datetime)\n",
    "ethn_list = convert('Int64', ethn_list, ints)\n",
    "ethn_list = oneHot(ethn_list, one_hots)\n",
    "ethn_list = dropCols(ethn_list, drop_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Process list variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### emar_medication\n",
    "This column is processed by finding the most common 5 medications among kidney disease patients.\n",
    "\n",
    "These five are then one-hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getLiterals(dfs, cols):\n",
    "    chars = \"[]''\"\n",
    "    for col in cols:\n",
    "        for df in range(len(dfs)):\n",
    "            dfs[df][col] = dfs[df][col].fillna(\"[]\")\n",
    "            for char in chars:\n",
    "                dfs[df][col] = dfs[df][col].apply(lambda x: x.replace(char, \"\"))\n",
    "            dfs[df][col] = dfs[df][col].apply(lambda x: x.split(\", \"))\n",
    "    return dfs\n",
    "\n",
    "def getUniquesInList(dfs, col):\n",
    "    uniques = set()\n",
    "    for df in range(len(dfs)):\n",
    "        kid_iss = dfs[df][dfs[df]['has_kidney_issue'] == True]\n",
    "        for item in kid_iss[col]:\n",
    "                for sub in item:\n",
    "                    uniques.add(sub)\n",
    "    return uniques\n",
    "\n",
    "def countMeds(dfs):\n",
    "    uniques = getUniquesInList(dfs, 'emar_medications')\n",
    "    meds = [0]*len(uniques)\n",
    "    # for every medicine found in patients with kidney issues\n",
    "    for i, med in enumerate(uniques):\n",
    "        # for every ethnicity\n",
    "        for df in range(len(dfs)):\n",
    "            kid_iss = dfs[df][dfs[df]['has_kidney_issue'] == True]\n",
    "            # for every patient's medications\n",
    "            for item in kid_iss['emar_medications']:\n",
    "                # if it contains the medicine, increment\n",
    "                if med in item:\n",
    "                    meds[i] += 1\n",
    "    return meds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ethn_list = getLiterals(ethn_list, ['emar_medications'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kidney_medications = getUniquesInList(ethn_list, 'emar_medications')\n",
    "kidney_medications = list(kidney_medications)\n",
    "\n",
    "med_count = np.genfromtxt('med_frequency.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# N most frequent meds\n",
    "N = 5\n",
    "\n",
    "inds = np.argsort(med_count)\n",
    "most_frequent = inds[-1]\n",
    "most_frequent = np.append(most_frequent, inds[-3])\n",
    "most_frequent = np.append(most_frequent, inds[-(N+2):-4])\n",
    "\n",
    "freq_med_names = []\n",
    "\n",
    "for item in most_frequent:\n",
    "    freq_med_names.append(kidney_medications[item])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def oneHotMeds(dfs, meds):\n",
    "    for med in meds:\n",
    "        for df in range(len(dfs)):\n",
    "            dfs[df][med] = False\n",
    "            for row in dfs[df].itertuples():\n",
    "                dfs[df].at[row.Index, med] = med in row.emar_medications\n",
    "    dfs = dropCols(dfs, ['emar_medications'])\n",
    "    return dfs\n",
    "\n",
    "ethn_list = oneHotMeds(ethn_list, freq_med_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for df in ethn_list:\n",
    "    df['admittime'] = pd.to_numeric(pd.to_datetime(df['admittime']))\n",
    "    df['icd_code_count'] = df['icd_code_count'].fillna(0)\n",
    "    df['emar_count'] = df['emar_count'].fillna(0)\n",
    "    df['lab_count'] = df['lab_count'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Abnormal lab flags\n",
    "The 'lab_flag' column is processed by counting the number of abnormal states\n",
    "\n",
    "EDIT: lab_flag column is dropped as its information is already encoded as lab_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def countAbnormal(dfs):\n",
    "    for df in range(len(dfs)):\n",
    "        for row in dfs[df].itertuples():\n",
    "                print(row.lab_flag.count('abnormal'))\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving  american_indian_alaska_native ...\n",
      "Saving  asian ...\n",
      "Saving  black_african_american ...\n",
      "Saving  hispanic_latino ...\n",
      "Saving  other ...\n",
      "Saving  unable_to_obtain ...\n",
      "Saving  unknown ...\n",
      "Saving  white ...\n"
     ]
    }
   ],
   "source": [
    "df_name = ['american_indian_alaska_native', 'asian', 'black_african_american', 'hispanic_latino', 'other', 'unable_to_obtain', 'unknown', 'white']\n",
    "\n",
    "for df in range(len(ethn_list)):\n",
    "    print(\"Saving \", df_name[df], \"...\")\n",
    "    ethn_list[df].to_csv(\"data/preprocessing_III/\" + df_name[df] + \".csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('sklearn-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "34e7f5b862476ca5b132d6fa3a551e06a58745cd7626854c77bc546bf08a4906"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
