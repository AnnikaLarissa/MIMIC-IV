{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "This files tests different parameters for the Random Forest classifier, and assess where the validation data reaches a maximum without overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "ethnic_group_names = ['unknown', 'white', 'other', 'asian', 'hispanic_latino', 'black_african_american',\n",
    "                      'unable_to_obtain', 'american_indian_alaska_native']\n",
    "path = './data/preprocessing_IV/'\n",
    "\n",
    "def read_train_val_test(name, path):\n",
    "    train = pd.read_csv(path + name + '_train.csv')\n",
    "    validate = pd.read_csv(path + name + '_validate.csv')\n",
    "    test = pd.read_csv(path + name + '_test.csv')\n",
    "    return train, validate, test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# split features and labels\n",
    "def splitFeaturesLabels(df):\n",
    "    X = df.copy()\n",
    "    X.drop('has_kidney_issue', axis=1)\n",
    "    # X = df[['anchor_age', 'anchor_year']]\n",
    "    return X, df.has_kidney_issue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tune(name, train, val):\n",
    "    # Initiate empty df to store results\n",
    "    results = pd.DataFrame({\"ethnicity\": [], \"max_depth\":[], \"n_estimators\":[], \"accuracy\":[]})\n",
    "\n",
    "    # split labels and features\n",
    "    # X = df[['hadm_id', 'subject_id', 'admittime', 'anchor_age', 'anchor_year', 'icd_code_count', 'emar_count', 'lab_count']]\n",
    "    # y = df['has_kidney_issue']\n",
    "\n",
    "    X_train, y_train = splitFeaturesLabels(train)\n",
    "    X_val, y_val = splitFeaturesLabels(val)\n",
    "\n",
    "    # split train and test\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    # try different values for max_depth of the individual trees\n",
    "    for depth in [6, 8, 10, 12, 14, 16, 18, 20]:\n",
    "        # try different values for the number of trees in a forest\n",
    "        for estimator in [10, 50, 100, 150, 200, 250, 300]:\n",
    "            # train classifier\n",
    "            clf = RandomForestClassifier(n_estimators=estimator, max_depth=depth, random_state=42)\n",
    "            clf.fit(X_train, y_train)\n",
    "            # predict labels\n",
    "            y_pred = clf.predict(X_val)\n",
    "            # calculate accuracy\n",
    "            accuracy = accuracy_score(y_val, y_pred)\n",
    "            # append results to df\n",
    "            new_result = pd.DataFrame({\"ethnicity\": name, \"max_depth\":depth, \"n_estimators\":estimator, \"accuracy\":accuracy}, index=[0])\n",
    "            results = pd.concat([results, new_result])\n",
    "    \n",
    "    # reset indexing\n",
    "    results = results.reset_index(drop=True)\n",
    "\n",
    "    # return\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getBestParams(df, results):\n",
    "    return df.append(results.loc[results['accuracy'].idxmax()])\n",
    "\n",
    "def tuneEachEthnicity(groups):\n",
    "    all_results = pd.DataFrame({\"ethnicity\": [], \"max_depth\":[], \"n_estimators\":[], \"accuracy\":[]})\n",
    "    for ethnicity in groups:\n",
    "        train, val, test = read_train_val_test(ethnicity, path)\n",
    "        results = tune(ethnicity, train, val)\n",
    "        all_results = getBestParams(all_results, results)\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2110-01-11 19:59:00'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m     results \u001B[38;5;241m=\u001B[39m tuneEachEthnicity(ethnic_group_names)\n\u001B[0;32m      3\u001B[0m     results\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhyperparameters.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 5\u001B[0m \u001B[43mrunToCSV\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36mrunToCSV\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrunToCSV\u001B[39m():\n\u001B[1;32m----> 2\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[43mtuneEachEthnicity\u001B[49m\u001B[43m(\u001B[49m\u001B[43methnic_group_names\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m     results\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhyperparameters.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Input \u001B[1;32mIn [5]\u001B[0m, in \u001B[0;36mtuneEachEthnicity\u001B[1;34m(groups)\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m ethnicity \u001B[38;5;129;01min\u001B[39;00m groups:\n\u001B[0;32m      7\u001B[0m     train, val, test \u001B[38;5;241m=\u001B[39m read_train_val_test(ethnicity, path)\n\u001B[1;32m----> 8\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[43mtune\u001B[49m\u001B[43m(\u001B[49m\u001B[43methnicity\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m     all_results \u001B[38;5;241m=\u001B[39m getBestParams(all_results, results)\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m all_results\n",
      "Input \u001B[1;32mIn [4]\u001B[0m, in \u001B[0;36mtune\u001B[1;34m(name, train, val)\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m estimator \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m50\u001B[39m, \u001B[38;5;241m100\u001B[39m, \u001B[38;5;241m150\u001B[39m, \u001B[38;5;241m200\u001B[39m, \u001B[38;5;241m250\u001B[39m, \u001B[38;5;241m300\u001B[39m]:\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;66;03m# train classifier\u001B[39;00m\n\u001B[0;32m     20\u001B[0m     clf \u001B[38;5;241m=\u001B[39m RandomForestClassifier(n_estimators\u001B[38;5;241m=\u001B[39mestimator, max_depth\u001B[38;5;241m=\u001B[39mdepth, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[1;32m---> 21\u001B[0m     \u001B[43mclf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     22\u001B[0m     \u001B[38;5;66;03m# predict labels\u001B[39;00m\n\u001B[0;32m     23\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m clf\u001B[38;5;241m.\u001B[39mpredict(X_val)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:327\u001B[0m, in \u001B[0;36mBaseForest.fit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m issparse(y):\n\u001B[0;32m    326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse multilabel-indicator for y is not supported.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 327\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    328\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmulti_output\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDTYPE\u001B[49m\n\u001B[0;32m    329\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    330\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    331\u001B[0m     sample_weight \u001B[38;5;241m=\u001B[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:581\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[1;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[0;32m    579\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[0;32m    580\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 581\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m check_X_y(X, y, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params)\n\u001B[0;32m    582\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[0;32m    584\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:964\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m    961\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    962\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my cannot be None\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 964\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    965\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    966\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    967\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    968\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    969\u001B[0m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    970\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    971\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    972\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    973\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_nd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    974\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    975\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    976\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    977\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    979\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric)\n\u001B[0;32m    981\u001B[0m check_consistent_length(X, y)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:746\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001B[0m\n\u001B[0;32m    744\u001B[0m         array \u001B[38;5;241m=\u001B[39m array\u001B[38;5;241m.\u001B[39mastype(dtype, casting\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124munsafe\u001B[39m\u001B[38;5;124m\"\u001B[39m, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    745\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 746\u001B[0m         array \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    747\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ComplexWarning \u001B[38;5;28;01mas\u001B[39;00m complex_warning:\n\u001B[0;32m    748\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    749\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mComplex data not supported\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(array)\n\u001B[0;32m    750\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcomplex_warning\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2064\u001B[0m, in \u001B[0;36mNDFrame.__array__\u001B[1;34m(self, dtype)\u001B[0m\n\u001B[0;32m   2063\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__array__\u001B[39m(\u001B[38;5;28mself\u001B[39m, dtype: npt\u001B[38;5;241m.\u001B[39mDTypeLike \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m np\u001B[38;5;241m.\u001B[39mndarray:\n\u001B[1;32m-> 2064\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_values\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: '2110-01-11 19:59:00'"
     ]
    }
   ],
   "source": [
    "def runToCSV():\n",
    "    results = tuneEachEthnicity(ethnic_group_names)\n",
    "    results.to_csv('hyperparameters.csv')\n",
    "\n",
    "runToCSV()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "white = tune('white')\n",
    "print(\"Highest accuracy:\\n\", white.loc[white['accuracy'].idxmax()])\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(white[\"max_depth\"], white[\"n_estimators\"], white[\"accuracy\"], cmap='viridis', edgecolor='none')\n",
    "ax.set_title(\"white\")\n",
    "ax.set_xlabel(\"max_depth\")\n",
    "ax.set_ylabel(\"n_estimators\")\n",
    "ax.set_zlabel(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "other = tune('other')\n",
    "print(\"Highest accuracy:\\n\", other.loc[other['accuracy'].idxmax()])\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(other[\"max_depth\"], other[\"n_estimators\"], other[\"accuracy\"], cmap='viridis', edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "asian = tune('asian')\n",
    "print(\"Highest accuracy:\\n\", asian.loc[asian['accuracy'].idxmax()])\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(asian[\"max_depth\"], asian[\"n_estimators\"], asian[\"accuracy\"], cmap='viridis', edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hispanic_latino = tune('hispanic_latino')\n",
    "print(\"Highest accuracy:\\n\", hispanic_latino.loc[hispanic_latino['accuracy'].idxmax()])\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(hispanic_latino[\"max_depth\"], hispanic_latino[\"n_estimators\"], hispanic_latino[\"accuracy\"], cmap='viridis', edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "black_african_american = tune('black_african_american')\n",
    "print(\"Highest accuracy:\\n\", black_african_american.loc[black_african_american['accuracy'].idxmax()])\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(black_african_american[\"max_depth\"], black_african_american[\"n_estimators\"], black_african_american[\"accuracy\"], cmap='viridis', edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unable_to_obtain = tune('unable_to_obtain')\n",
    "print(\"Highest accuracy:\\n\", unable_to_obtain.loc[unable_to_obtain['accuracy'].idxmax()])\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(unable_to_obtain[\"max_depth\"], unable_to_obtain[\"n_estimators\"], unable_to_obtain[\"accuracy\"], cmap='viridis', edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "american_indian_alaska_native = tune('american_indian_alaska_native')\n",
    "print(\"Highest accuracy:\\n\", american_indian_alaska_native.loc[american_indian_alaska_native['accuracy'].idxmax()])\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(american_indian_alaska_native[\"max_depth\"], american_indian_alaska_native[\"n_estimators\"], american_indian_alaska_native[\"accuracy\"], cmap='viridis', edgecolor='none')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('sklearn-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34e7f5b862476ca5b132d6fa3a551e06a58745cd7626854c77bc546bf08a4906"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}