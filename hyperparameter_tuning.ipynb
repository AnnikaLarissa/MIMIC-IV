{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "This files tests different parameters for the Random Forest classifier, and assess where the validation data reaches a maximum without overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ethnic_group_names = ['unknown', 'white', 'other', 'asian', 'hispanic_latino', 'black_african_american',\n",
    "                      'unable_to_obtain', 'american_indian_alaska_native']\n",
    "path = './data/preprocessing_IV/'\n",
    "\n",
    "def read_train_val_test(name, path):\n",
    "    train = pd.read_csv(path + name + '_train.csv')\n",
    "    # NOTE: drope datetime columns for now, because sklearn does not support it\n",
    "    train = train.drop(columns=['admittime', 'edregtime', 'emar_charttime', 'lab_charttime'])\n",
    "    validate = pd.read_csv(path + name + '_validate.csv')\n",
    "    # NOTE: drope datetime columns for now, because sklearn does not support it\n",
    "    validate = validate.drop(columns=['admittime', 'edregtime', 'emar_charttime', 'lab_charttime'])\n",
    "    test = pd.read_csv(path + name + '_test.csv')\n",
    "    # NOTE: drope datetime columns for now, because sklearn does not support it\n",
    "    test = test.drop(columns=['admittime', 'edregtime', 'emar_charttime', 'lab_charttime'])\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# split features and labels\n",
    "def splitFeaturesLabels(df):\n",
    "    X = df.copy()\n",
    "    X.drop('has_kidney_issue', axis=1)\n",
    "    # X = df[['anchor_age', 'anchor_year']]\n",
    "    return X, df.has_kidney_issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tune(name, train, val):\n",
    "    # Initiate empty df to store results\n",
    "    results = pd.DataFrame({\"ethnicity\": [], \"max_depth\":[], \"n_estimators\":[], \"accuracy\":[]})\n",
    "\n",
    "    # split labels and features\n",
    "    # X = df[['hadm_id', 'subject_id', 'admittime', 'anchor_age', 'anchor_year', 'icd_code_count', 'emar_count', 'lab_count']]\n",
    "    # y = df['has_kidney_issue']\n",
    "\n",
    "    X_train, y_train = splitFeaturesLabels(train)\n",
    "    X_val, y_val = splitFeaturesLabels(val)\n",
    "\n",
    "    # split train and test\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    # try different values for max_depth of the individual trees\n",
    "    for depth in [6, 8, 10, 12, 14, 16, 18, 20]:\n",
    "        # try different values for the number of trees in a forest\n",
    "        for estimator in [10, 50, 100, 150, 200, 250, 300]:\n",
    "            # train classifier\n",
    "            clf = RandomForestClassifier(n_estimators=estimator, max_depth=depth, random_state=42)\n",
    "            clf.fit(X_train, y_train)\n",
    "            # predict labels\n",
    "            y_pred = clf.predict(X_val)\n",
    "            # calculate accuracy\n",
    "            accuracy = accuracy_score(y_val, y_pred)\n",
    "            # append results to df\n",
    "            new_result = pd.DataFrame({\"ethnicity\": name, \"max_depth\":depth, \"n_estimators\":estimator, \"accuracy\":accuracy}, index=[0])\n",
    "            results = pd.concat([results, new_result])\n",
    "    \n",
    "    # reset indexing\n",
    "    results = results.reset_index(drop=True)\n",
    "\n",
    "    # return\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def getBestParams(df, results):\n",
    "    return df.append(results.loc[results['accuracy'].idxmax()])\n",
    "\n",
    "def tuneEachEthnicity(groups):\n",
    "    all_results = pd.DataFrame({\"ethnicity\": [], \"max_depth\":[], \"n_estimators\":[], \"accuracy\":[]})\n",
    "    for ethnicity in groups:\n",
    "        train, val, test = read_train_val_test(ethnicity, path)\n",
    "        results = tune(ethnicity, train, val)\n",
    "        all_results = getBestParams(all_results, results)\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annik\\AppData\\Local\\Temp\\ipykernel_15484\\771118452.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  return df.append(results.loc[results['accuracy'].idxmax()])\n",
      "C:\\Users\\annik\\AppData\\Local\\Temp\\ipykernel_15484\\771118452.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  return df.append(results.loc[results['accuracy'].idxmax()])\n",
      "C:\\Users\\annik\\AppData\\Local\\Temp\\ipykernel_15484\\771118452.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  return df.append(results.loc[results['accuracy'].idxmax()])\n",
      "C:\\Users\\annik\\AppData\\Local\\Temp\\ipykernel_15484\\771118452.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  return df.append(results.loc[results['accuracy'].idxmax()])\n",
      "C:\\Users\\annik\\AppData\\Local\\Temp\\ipykernel_15484\\771118452.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  return df.append(results.loc[results['accuracy'].idxmax()])\n",
      "C:\\Users\\annik\\AppData\\Local\\Temp\\ipykernel_15484\\771118452.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  return df.append(results.loc[results['accuracy'].idxmax()])\n",
      "C:\\Users\\annik\\AppData\\Local\\Temp\\ipykernel_15484\\771118452.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  return df.append(results.loc[results['accuracy'].idxmax()])\n",
      "C:\\Users\\annik\\AppData\\Local\\Temp\\ipykernel_15484\\771118452.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  return df.append(results.loc[results['accuracy'].idxmax()])\n"
     ]
    }
   ],
   "source": [
    "def runToCSV():\n",
    "    results = tuneEachEthnicity(ethnic_group_names)\n",
    "    results.to_csv('hyperparameters.csv')\n",
    "\n",
    "runToCSV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tune() missing 2 required positional arguments: 'train' and 'val'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Users\\annik\\Documenten\\Zweden\\KTH\\S1\\Research Methodology\\MIMIC-IV\\hyperparameter_tuning.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Users/annik/Documenten/Zweden/KTH/S1/Research%20Methodology/MIMIC-IV/hyperparameter_tuning.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m white \u001b[39m=\u001b[39m tune(\u001b[39m'\u001b[39;49m\u001b[39mwhite\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/annik/Documenten/Zweden/KTH/S1/Research%20Methodology/MIMIC-IV/hyperparameter_tuning.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mHighest accuracy:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, white\u001b[39m.\u001b[39mloc[white[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39midxmax()])\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Users/annik/Documenten/Zweden/KTH/S1/Research%20Methodology/MIMIC-IV/hyperparameter_tuning.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39maxes(projection\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m3d\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: tune() missing 2 required positional arguments: 'train' and 'val'"
     ]
    }
   ],
   "source": [
    "white = tune('white')\n",
    "print(\"Highest accuracy:\\n\", white.loc[white['accuracy'].idxmax()])\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(white[\"max_depth\"], white[\"n_estimators\"], white[\"accuracy\"], cmap='viridis', edgecolor='none')\n",
    "ax.set_title(\"white\")\n",
    "ax.set_xlabel(\"max_depth\")\n",
    "ax.set_ylabel(\"n_estimators\")\n",
    "ax.set_zlabel(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "other = tune('other')\n",
    "print(\"Highest accuracy:\\n\", other.loc[other['accuracy'].idxmax()])\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(other[\"max_depth\"], other[\"n_estimators\"], other[\"accuracy\"], cmap='viridis', edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "asian = tune('asian')\n",
    "print(\"Highest accuracy:\\n\", asian.loc[asian['accuracy'].idxmax()])\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(asian[\"max_depth\"], asian[\"n_estimators\"], asian[\"accuracy\"], cmap='viridis', edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hispanic_latino = tune('hispanic_latino')\n",
    "print(\"Highest accuracy:\\n\", hispanic_latino.loc[hispanic_latino['accuracy'].idxmax()])\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(hispanic_latino[\"max_depth\"], hispanic_latino[\"n_estimators\"], hispanic_latino[\"accuracy\"], cmap='viridis', edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "black_african_american = tune('black_african_american')\n",
    "print(\"Highest accuracy:\\n\", black_african_american.loc[black_african_american['accuracy'].idxmax()])\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(black_african_american[\"max_depth\"], black_african_american[\"n_estimators\"], black_african_american[\"accuracy\"], cmap='viridis', edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "unable_to_obtain = tune('unable_to_obtain')\n",
    "print(\"Highest accuracy:\\n\", unable_to_obtain.loc[unable_to_obtain['accuracy'].idxmax()])\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(unable_to_obtain[\"max_depth\"], unable_to_obtain[\"n_estimators\"], unable_to_obtain[\"accuracy\"], cmap='viridis', edgecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "american_indian_alaska_native = tune('american_indian_alaska_native')\n",
    "print(\"Highest accuracy:\\n\", american_indian_alaska_native.loc[american_indian_alaska_native['accuracy'].idxmax()])\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(american_indian_alaska_native[\"max_depth\"], american_indian_alaska_native[\"n_estimators\"], american_indian_alaska_native[\"accuracy\"], cmap='viridis', edgecolor='none')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('sklearn-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34e7f5b862476ca5b132d6fa3a551e06a58745cd7626854c77bc546bf08a4906"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
