{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Preprocessing MIMIC-IV\n",
    "\n",
    "This file aggregates the relevant data tables and stores them as .csv per ethnic group. To do so, we use DASK to handle the large data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import dask\n",
    "from dask import dataframe as dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Core Data\n",
    "\n",
    "Imports all data about patients (age, ethnicity, etc.). We remove all columns that the doctor does not need or cannot have while making a diagnoses. For example: as a patient comes in and the doctor makes a diagnose, the doctor does not know yet what the 'dischtime' will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_core_data ():\n",
    "    # Load in gzip compressed data with Dask\n",
    "    # Parallelism is not supported on gzip -> blocksize=none\n",
    "    admissions = dd.read_csv(\"mimic-iv-0.4/core/admissions.csv.gz\", blocksize=None, dtype={'deathtime': 'object'})\n",
    "    patients = dd.read_csv(\"mimic-iv-0.4/core/patients.csv.gz\", blocksize=None)\n",
    "\n",
    "    # Merge dataframes\n",
    "    core = admissions.merge(patients, on=\"subject_id\")\n",
    "\n",
    "    # Select only the columns that are know at the patients' arrival\n",
    "    core = core[['subject_id', 'hadm_id', 'admittime', 'admission_type', 'admission_location',\n",
    "        'insurance', 'marital_status', 'ethnicity', 'edregtime',\n",
    "        'gender', 'anchor_age', 'anchor_year']]\n",
    "    \n",
    "    core = core.set_index(\"hadm_id\")\n",
    "    \n",
    "    return core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Split ethnicities\n",
    "\n",
    "Create a dataframe for each ethnic group. The goal is to output one aggregated .csv for each etnicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def split_ethnicities (core):\n",
    "    # ethnicities = ['UNKNOWN', 'WHITE', 'OTHER', 'ASIAN', 'HISPANIC/LATINO','BLACK/AFRICAN AMERICAN', 'UNABLE TO OBTAIN','AMERICAN INDIAN/ALASKA NATIVE']\n",
    "    ethnicities = core['ethnicity'].unique()\n",
    "\n",
    "    print(\"Number of data subjects per ethnicity:\")\n",
    "\n",
    "    count = core.groupby('ethnicity').ethnicity.count()\n",
    "    count = count.compute()\n",
    "    print(count)\n",
    "\n",
    "    # Create dataframe for each ethnicity\n",
    "    unknown = core[core['ethnicity'] == 'UNKNOWN']\n",
    "    white = core[core['ethnicity'] == 'WHITE']\n",
    "    other = core[core['ethnicity'] == 'OTHER']\n",
    "    asian = core[core['ethnicity'] == 'ASIAN']\n",
    "    hispanic_latino = core[core['ethnicity'] == 'HISPANIC/LATINO']\n",
    "    black_african_american = core[core['ethnicity'] == 'BLACK/AFRICAN AMERICAN']\n",
    "    unable_to_obtain = core[core['ethnicity'] == 'UNABLE TO OBTAIN']\n",
    "    american_indian_alaska_native = core[core['ethnicity'] == 'AMERICAN INDIAN/ALASKA NATIVE']\n",
    "\n",
    "    return unknown, white, other, asian, hispanic_latino, black_african_american, unable_to_obtain, american_indian_alaska_native"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Hosp Data\n",
    "\n",
    "### Add icd\n",
    "\"International Statistical Classification of Diseases and Related Health Problems (ICD) serves a broad range of uses globally and provides critical knowledge on the extent, causes and consequences of human disease and death worldwide via data that is reported and coded with the ICD.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_icd (ethnic_group):\n",
    "    # Table that connects patiets' hospital visits to icd_codes\n",
    "    # ['subject_id', 'hadm_id', 'seq_num', 'icd_code', 'icd_version']\n",
    "    diagnoses_icd = dd.read_csv(\"mimic-iv-0.4/hosp/diagnoses_icd.csv.gz\", blocksize=None, dtype={'icd_code': 'object'})\n",
    "    diagnoses_icd = diagnoses_icd[['hadm_id', 'icd_code']]\n",
    "\n",
    "    # Create icd_code list + counts for each hadm_id\n",
    "    icd_counts = diagnoses_icd.groupby('hadm_id').count()\n",
    "    icd_counts = icd_counts.rename(columns={'icd_code':'icd_code_count'})\n",
    "    diagnoses_icd = diagnoses_icd.groupby('hadm_id').agg(list)\n",
    "    diagnoses_icd = diagnoses_icd.merge(icd_counts, how='left', on='hadm_id')\n",
    "    \n",
    "    # Merge\n",
    "    core_hosp_prelim = ethnic_group.merge(diagnoses_icd, how='left', on='hadm_id')\n",
    "\n",
    "    # Add table with icd_code descriptions\n",
    "    # ['icd_code', 'icd_version', 'long_title']\n",
    "    # d_icd_diagnoses = dd.read_csv(\"mimic-iv-0.4/hosp/d_icd_diagnoses.csv.gz\", blocksize=None, dtype={'icd_code': 'object'})\n",
    "    # d_icd_diagnoses = d_icd_diagnoses[['icd_code', 'long_title']].copy()\n",
    "    # d_icd_diagnoses = d_icd_diagnoses.rename(columns={'long_title':'icd_name'})\n",
    "    # core_hosp_prelim = core_hosp_prelim.merge(d_icd_diagnoses, how=\"left\", on=\"icd_code\")\n",
    "\n",
    "    # Add table with icd sequence numbers\n",
    "    # ['subject_id', 'hadm_id', 'seq_num', 'icd_code', 'icd_version']\n",
    "    # procedures_icd = dd.read_csv(\"mimic-iv-0.4/hosp/procedures_icd.csv.gz\", blocksize=None, dtype={'icd_code': 'object'})\n",
    "    # procedures_icd = procedures_icd[['hadm_id', 'seq_num', 'icd_code']].copy()\n",
    "    # procedures_icd = procedures_icd.rename(columns={'seq_num': \"icd_seq_num\"})\n",
    "    # core_hosp_prelim = core_hosp_prelim.merge(procedures_icd, how=\"left\", on=['hadm_id', 'icd_code'])\n",
    "    # core_hosp_prelim = core_hosp_prelim.set_index(\"hadm_id\")\n",
    "\n",
    "    return core_hosp_prelim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Add emar\n",
    "\"The primary function of eMAR is to electronically track and record resident administration of medication and treatments.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_emar (core_hosp_prelim):\n",
    "    # Add table containing medication information\n",
    "    # ['subject_id', 'hadm_id', 'emar_id', 'emar_seq', 'poe_id', 'pharmacy_id', 'charttime', 'medication', 'event_txt', 'scheduletime', 'storetime']\n",
    "    emar = dd.read_csv(\"mimic-iv-0.4/hosp/emar.csv\")\n",
    "    emar = emar[['hadm_id', 'charttime', 'medication', 'event_txt']].copy()\n",
    "    emar = emar.rename(columns={'charttime':'emar_charttime', 'medication':'emar_medication', 'event_txt':'emar_event'})\n",
    "\n",
    "    # Drop NaN in hadm_id and convert to int64 (like all other tables)\n",
    "    emar = emar.dropna(subset=\"hadm_id\")\n",
    "    emar = emar.astype({'hadm_id': 'int64'})\n",
    "\n",
    "    # Groupby hadm_id (this prevents computing the same thing over and over)\n",
    "    emar_groupby_hamdid = emar.groupby('hadm_id')\n",
    "\n",
    "    # Create counts for each hadm_id + convert to dataframe\n",
    "    emar_counts = emar_groupby_hamdid['emar_medication'].count()\n",
    "    emar_prelim = emar_counts.to_frame()\n",
    "    emar_prelim = emar_prelim.rename(columns={'emar_medication':'emar_count'})\n",
    "\n",
    "    # Add first charttime (it looks like 1 hadm_id only has 1 charttime anyways)\n",
    "    emar_charttime = emar_groupby_hamdid['emar_charttime'].min()\n",
    "    emar_prelim['emar_charttime'] = emar_charttime\n",
    "\n",
    "    # Add medication list for each hadm_id\n",
    "    emar_medications = emar_groupby_hamdid['emar_medication'].agg(list)\n",
    "    emar_prelim['emar_medications'] = emar_medications\n",
    "\n",
    "    # Add event list for each hadm_id\n",
    "    emar_events = emar_groupby_hamdid['emar_event'].agg(list)\n",
    "    emar_prelim['emar_events'] = emar_events\n",
    "\n",
    "    # Merge \n",
    "    core_hosp_prelim = core_hosp_prelim.merge(emar_prelim, how=\"left\", on=[\"hadm_id\"])\n",
    "\n",
    "    return core_hosp_prelim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Add labevents\n",
    "\n",
    "Measurements that have been obtained outside of the hospital on e.g. blood/urine/etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def add_labevents (core_hosp_prelim):\n",
    "    # Add table containing the lab results\n",
    "    # ['labevent_id', 'subject_id', 'hadm_id', 'specimen_id', 'itemid','charttime', 'storetime', 'value', 'valuenum', 'valueuom','ref_range_lower', 'ref_range_upper', 'flag', 'priority', 'comments']\n",
    "    labevents= dd.read_csv(\"mimic-iv-0.4/hosp/labevents.csv\", dtype={'comments': 'object', 'hadm_id': 'float64', 'value': 'object', 'valueuom': 'object', 'flag': 'object'})\n",
    "    labevents = labevents[['hadm_id', 'charttime', 'flag', 'priority', 'comments']]\n",
    "    labevents = labevents.rename(columns={'charttime': 'lab_charttime', 'flag': 'lab_flag', 'priority': 'lab_priority', 'comments': 'lab_comments'})\n",
    "\n",
    "    # Drop NaN in hadm_id and convert to int64 (like all other tables)\n",
    "    labevents = labevents.dropna(subset=\"hadm_id\")\n",
    "    labevents = labevents.astype({'hadm_id': 'int64'})\n",
    "\n",
    "    # Groupby hadm_id (this prevents computing the same thing over and over)\n",
    "    labevents_groupby_hamdid = labevents.groupby('hadm_id')\n",
    "\n",
    "    # Create counts for each hadm_id + convert to dataframe\n",
    "    labevents_counts = labevents_groupby_hamdid['lab_flag'].count()\n",
    "    labevents_prelim = labevents_counts.to_frame()\n",
    "    labevents_prelim = labevents_prelim.rename(columns={'lab_flag':'lab_count'})\n",
    "\n",
    "    # Add first charttime (it looks like 1 hadm_id only has 1 charttime anyways)\n",
    "    labevents_charttime = labevents_groupby_hamdid['lab_charttime'].min()\n",
    "    labevents_prelim['lab_charttime'] = labevents_charttime\n",
    "\n",
    "    # Add flag list for each hadm_id\n",
    "    labevents_flag = labevents_groupby_hamdid['lab_flag'].agg(list)\n",
    "    labevents_prelim['lab_flag'] = labevents_flag\n",
    "\n",
    "    # Add priority list for each hadm_id\n",
    "    labevents_priority = labevents_groupby_hamdid['lab_priority'].agg(list)\n",
    "    labevents_prelim['lab_priority'] = labevents_priority\n",
    "\n",
    "    # Add comments list for each hadm_id\n",
    "    labevents_comments = labevents_groupby_hamdid['lab_comments'].agg(list)\n",
    "    labevents_prelim['lab_comments'] = labevents_comments\n",
    "\n",
    "    # Merge \n",
    "    core_hosp_prelim = core_hosp_prelim.merge(labevents_prelim, how=\"left\", on=[\"hadm_id\"])\n",
    "\n",
    "    return core_hosp_prelim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Run everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core data loaded...\n",
      "Number of data subjects per ethnicity:\n",
      "ethnicity\n",
      "AMERICAN INDIAN/ALASKA NATIVE      1536\n",
      "ASIAN                             24522\n",
      "BLACK/AFRICAN AMERICAN            80526\n",
      "HISPANIC/LATINO                   29887\n",
      "OTHER                             26844\n",
      "UNABLE TO OBTAIN                   3742\n",
      "UNKNOWN                           19419\n",
      "WHITE                            338044\n",
      "Name: ethnicity, dtype: int64\n",
      "Adding icd data for group:  unknown ...\n",
      "Adding emar data for group:  unknown ...\n",
      "Adding lab data for group:  unknown ...\n",
      "Saving .csv file for group:  unknown ...\n",
      "Adding icd data for group:  white ...\n",
      "Adding emar data for group:  white ...\n",
      "Adding lab data for group:  white ...\n",
      "Saving .csv file for group:  white ...\n",
      "Adding icd data for group:  other ...\n",
      "Adding emar data for group:  other ...\n",
      "Adding lab data for group:  other ...\n",
      "Saving .csv file for group:  other ...\n",
      "Adding icd data for group:  asian ...\n",
      "Adding emar data for group:  asian ...\n",
      "Adding lab data for group:  asian ...\n",
      "Saving .csv file for group:  asian ...\n",
      "Adding icd data for group:  hispanic_latino ...\n",
      "Adding emar data for group:  hispanic_latino ...\n",
      "Adding lab data for group:  hispanic_latino ...\n",
      "Saving .csv file for group:  hispanic_latino ...\n",
      "Adding icd data for group:  black_african_american ...\n",
      "Adding emar data for group:  black_african_american ...\n",
      "Adding lab data for group:  black_african_american ...\n",
      "Saving .csv file for group:  black_african_american ...\n",
      "Adding icd data for group:  unable_to_obtain ...\n",
      "Adding emar data for group:  unable_to_obtain ...\n",
      "Adding lab data for group:  unable_to_obtain ...\n",
      "Saving .csv file for group:  unable_to_obtain ...\n",
      "Adding icd data for group:  american_indian_alaska_native ...\n",
      "Adding emar data for group:  american_indian_alaska_native ...\n",
      "Adding lab data for group:  american_indian_alaska_native ...\n",
      "Saving .csv file for group:  american_indian_alaska_native ...\n"
     ]
    }
   ],
   "source": [
    "# Dataframe with Selected columns of core data \n",
    "# (patients' age, ethnicity, etc.)\n",
    "core = load_core_data()\n",
    "print(\"Core data loaded...\")\n",
    "\n",
    "# One dataframe with core data per ethnic group\n",
    "unknown, white, other, asian, hispanic_latino, black_african_american, unable_to_obtain, american_indian_alaska_native = split_ethnicities(core)\n",
    "# List of dataframes\n",
    "ethnic_groups = [unknown, white, other, asian, hispanic_latino, black_african_american, unable_to_obtain, american_indian_alaska_native]\n",
    "# List of ethnic group names\n",
    "ethnic_group_names = ['unknown', 'white', 'other', 'asian', 'hispanic_latino', 'black_african_american', 'unable_to_obtain', 'american_indian_alaska_native']\n",
    "\n",
    "# Add hospital data to each ethnic group dataframe\n",
    "# Save dataframes as seperate csv files\n",
    "for i in range (0, len(ethnic_groups)):\n",
    "    # Add icd data\n",
    "    # (classification of diseases)\n",
    "    print(\"Adding icd data for group: \", ethnic_group_names[i], \"...\")\n",
    "    core_hosp_prelim = add_icd(ethnic_groups[i])\n",
    "\n",
    "    # Add emar data \n",
    "    # (medication and treatment)\n",
    "    print(\"Adding emar data for group: \", ethnic_group_names[i], \"...\")\n",
    "    core_hosp_prelim = add_emar(core_hosp_prelim)\n",
    "    \n",
    "    # Add lab data \n",
    "    # (blood/urine/etc. inspection)\n",
    "    print(\"Adding lab data for group: \", ethnic_group_names[i], \"...\")\n",
    "    core_hosp_prelim = add_labevents(core_hosp_prelim)\n",
    "    \n",
    "    # Save as .csv\n",
    "    print(\"Saving .csv file for group: \", ethnic_group_names[i], \"...\")\n",
    "    path = \"data/preprocessing_I/\" + ethnic_group_names[i] + \".csv\"\n",
    "    core_hosp_prelim.to_csv(path, single_file = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4476010b776233d468c3518ff18be3b14f9a5a396f0f21819cda90a234c3199b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}